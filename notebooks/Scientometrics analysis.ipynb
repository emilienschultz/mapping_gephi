{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse publications on Gephi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data : all publications with a mention of Gephi somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"../Data/scopus_all.csv\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the software used with Gephi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter articles with Gephi in the abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = data[\"Abstract\"].str.lower().str.contains(\"gephi\")\n",
    "df_sub = data[f]\n",
    "df_sub.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use of Gliner to extract software mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_large-v2.1\")\n",
    "\n",
    "def split_text(text, chunck=300):\n",
    "    chuncks = [text[i:i + chunck] for i in range(0, len(text), chunck)]\n",
    "    return chuncks\n",
    "\n",
    "def get_softwares(text):\n",
    "    chucks = split_text(text)\n",
    "    total = []\n",
    "    for c in chucks:\n",
    "        total += [i[\"text\"].lower().strip() for i in model.predict_entities(c, labels=[\"Software\"])]\n",
    "    return list(set(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spss', 'exc', 'gephi']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_softwares(data[f][\"Abstract\"].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f9/d2d_05ws5gncmml0fx0c00kw0000gp/T/ipykernel_85694/3405983463.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sub[\"softwares\"] = df_sub[\"Abstract\"].apply(get_softwares)\n"
     ]
    }
   ],
   "source": [
    "df_sub[\"softwares\"] = df_sub[\"Abstract\"].apply(get_softwares)\n",
    "df_sub.to_csv(\"scopus_gephi_softwaredetect.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual cleaning of software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame(pd.Series([j for i in df_sub[\"softwares\"] for j in i]).value_counts()).reset_index()\n",
    "t.columns = [\"name\",\"count\"]\n",
    "#t.to_csv(\"reco_software.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the list of cleaned software (careful, there is always the problem of identifying pattern and rematching them from a list, with polysemia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f9/d2d_05ws5gncmml0fx0c00kw0000gp/T/ipykernel_85694/221137104.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sub[\"softwares_reco\"] = df_sub[\"Abstract\"].apply(lambda x : get_softwares(x, softwares))\n"
     ]
    }
   ],
   "source": [
    "softwares = list(pd.read_csv(\"reco_software.csv\")[\"name\"])[0:100]\n",
    "\n",
    "def get_softwares(texte, liste):\n",
    "    \"\"\"\n",
    "    Rematch the software names\n",
    "    \"\"\"\n",
    "    return [i for i in liste if i.lower() in texte.lower()]\n",
    "\n",
    "df_sub[\"softwares_reco\"] = df_sub[\"Abstract\"].apply(lambda x : get_softwares(x, softwares))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 94 nodes and 511 edges\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "reseau = nx.Graph()\n",
    "\n",
    "def recode(x):\n",
    "    if \"gephi\" in x.lower():\n",
    "        return \"gephi\"\n",
    "    return x\n",
    "\n",
    "for softwares in df_sub[\"softwares_reco\"]:\n",
    "    \n",
    "    softwares = [recode(x) for x in softwares]\n",
    "\n",
    "    for s in softwares:\n",
    "        s = s.lower()\n",
    "        if \"gephi\" in s:\n",
    "            s = \"gephi\"\n",
    "        if not reseau.has_node(s):\n",
    "            reseau.add_node(s, weight=0)\n",
    "        reseau.nodes[s][\"weight\"]+=1\n",
    "    for a,b in combinations(softwares,2):\n",
    "        if not reseau.has_edge(a,b):\n",
    "            reseau.add_edge(a,b,weight=0)\n",
    "        reseau.edges[a,b][\"weight\"]+=1\n",
    "    \n",
    "reseau.remove_node(\"gephi\")\n",
    "print(reseau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844dc4bad92d4609b8ebc2e8e87f2d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sigma(nx.Graph with 94 nodes and 511 edges)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipysigma import Sigma\n",
    "Sigma(reseau, node_size=\"weight\", edge_size=\"weight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
